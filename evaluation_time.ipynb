{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: 6a6058df1898\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from surface_dice import SurfaceDiceMetric\n",
    "import albumentations as A\n",
    "import random\n",
    "import segmentation_models_pytorch as smp\n",
    "from patcher import Patcher\n",
    "\n",
    "hostname = os.uname().nodename\n",
    "print(\"Hostname:\", hostname)\n",
    "input_dir = \"data/blood-vessel-segmentation/\" if hostname == \"gamma\" else \"/kaggle/input/blood-vessel-segmentation/\"\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dir = input_dir + \"train/\"\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KidneyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs_dir, msks_dir, slices_ids, transforms=None):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.msks_dir = msks_dir\n",
    "        self.slices_ids = slices_ids\n",
    "        self.transforms = transforms\n",
    "        self.h = Image.open(imgs_dir + slices_ids[0]).height\n",
    "        self.w = Image.open(imgs_dir + slices_ids[0]).width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            \n",
    "        slice_id = self.slices_ids[idx]\n",
    "        img_path = self.imgs_dir + slice_id\n",
    "        msk_path = self.msks_dir + slice_id\n",
    "\n",
    "        img = np.array(Image.open(img_path), dtype=np.float32)\n",
    "        msk = np.array(Image.open(msk_path))\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            t = self.transforms(image=img, mask=msk)\n",
    "            img = t[\"image\"]\n",
    "            msk = t[\"mask\"]\n",
    "            \n",
    "        img = torch.from_numpy(img)[None, :]\n",
    "        msk = torch.from_numpy(msk)\n",
    "        img /= 31000 \n",
    "        msk = msk // 255 \n",
    "\n",
    "        return img, msk\n",
    "\n",
    "class KidneyDatasetPrefetched(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds, imgs_file=None, msks_file=None):\n",
    "        from_file = imgs_file is not None and msks_file is not None\n",
    "        print(\"From file:\", from_file)\n",
    "        if from_file:\n",
    "            self.imgs = torch.load(imgs_file)\n",
    "            self.msks = torch.load(msks_file)\n",
    "        else:\n",
    "            dl = DataLoader(ds, batch_size=len(ds), shuffle=False, persistent_workers=False)\n",
    "            self.imgs, self.msks = next(iter(dl))\n",
    "\n",
    "        self.h, self.w = self.imgs.shape[-2:]\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.msks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import ceil\n",
    "\n",
    "class PatcherNew:\n",
    "    def __init__(self, h, w, p_size, overlap):\n",
    "        self.h, self.w = h, w\n",
    "        self.p_size = p_size\n",
    "        self.overlap = overlap\n",
    "\n",
    "        self.stride = p_size - overlap\n",
    "        self.h_pad = self.stride * ceil((h - p_size) / self.stride) + p_size - h\n",
    "        self.w_pad = self.stride * ceil((w - p_size) / self.stride) + p_size - w\n",
    "\n",
    "        self.unfold = torch.nn.Unfold(kernel_size=(p_size, p_size), stride=self.stride)\n",
    "        self.fold = torch.nn.Fold(\n",
    "            output_size=(h + self.h_pad, w + self.w_pad),\n",
    "            kernel_size=(p_size, p_size),\n",
    "            stride=self.stride\n",
    "        )\n",
    "\n",
    "    def extract_patches(self, x):\n",
    "        assert x.ndim == 4\n",
    "        x = F.pad(x, (0, self.w_pad, 0, self.h_pad), mode=\"reflect\")\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        patches = x.unfold(2, self.p_size, self.stride).unfold(3, self.p_size, self.stride)  # (B, C, h_steps, w_steps, p_size, p_size)\n",
    "        patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()                             # (B, h_steps, w_steps, C, p_size, p_size)\n",
    "        patches = patches.view(B, -1, C, self.p_size, self.p_size)                           # (B, n_patches, p_size, p_size)\n",
    "        return patches\n",
    "    \n",
    "    def merge_patches(self, patches):\n",
    "        assert patches.ndim == 5\n",
    "        B, N, C, _, _ = patches.shape\n",
    "\n",
    "        # fold expects the patches tensor to have a shape (B, C * p_size * p_size, N)\n",
    "        x = patches.permute(0, 2, 3, 4, 1).view(B, C * self.p_size * self.p_size, N)  \n",
    "        x = self.fold(x)  # (B, C, h + pad_h, w + pad_w)\n",
    "\n",
    "        # as patches overlap we average the values of overlapping pixels\n",
    "        weight_mask = 1 / self.fold(self.unfold(torch.ones(x.shape[-3:], device=patches.device)))\n",
    "        x = x * weight_mask\n",
    "\n",
    "        x = x[:, :, :self.h, :self.w]\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = f\"{train_dir}kidney_1_dense/images/\"\n",
    "msks_dir = f\"{train_dir}kidney_1_dense/labels/\"\n",
    "slices_ids = sorted(os.listdir(imgs_dir))\n",
    "\n",
    "patch_size = 224\n",
    "\n",
    "eval_ds = KidneyDataset(\n",
    "    imgs_dir=imgs_dir,\n",
    "    msks_dir=msks_dir,\n",
    "    slices_ids=slices_ids,\n",
    ")\n",
    "\n",
    "# eval_ds = KidneyDatasetPrefetched(eval_ds, imgs_file=\"kidney_1_imgs_prefetched.pth\", msks_file=\"kidney_1_msks_prefetched.pth\")\n",
    "# eval_ds = KidneyDatasetPrefetched(eval_ds)\n",
    "\n",
    "eval_dl = DataLoader(\n",
    "    eval_ds,\n",
    "    batch_size=16,\n",
    "    num_workers=8 if hostname == \"gamma\" else 2,\n",
    "    shuffle=False,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "h = eval_ds.h\n",
    "w = eval_ds.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = smp.Unet(\n",
    "    encoder_name=\"timm-mobilenetv3_small_075\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ")\n",
    "net.load_state_dict(torch.load(\"baseline_train_sdc_0.727.pth\"))\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:59<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# for x, y in tqdm(eval_dl):\n",
    "#     x, y = x.to(device), y.to(device).float()\n",
    "\n",
    "overlap = 50\n",
    "patcher = PatcherNew(h, w, p_size=patch_size, overlap=overlap)\n",
    "for x, y in tqdm(eval_dl):\n",
    "    bs = len(x)\n",
    "    x, y = x.to(device), y.to(device).float()\n",
    "    x = patcher.extract_patches(x)\n",
    "    x = patcher.merge_patches(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_old(save_preds=False):\n",
    "    overlap = 50\n",
    "    patcher = Patcher(h, w, patch_size=patch_size, overlap=overlap)\n",
    "    eval_loss = 0.0\n",
    "    idx = 0\n",
    "    net.eval()\n",
    "    metric = SurfaceDiceMetric(n_batches=len(eval_dl), device=device)\n",
    "    for x, y in tqdm(eval_dl):\n",
    "        bs = len(x)\n",
    "        x, y = x.to(device), y.to(device).float()\n",
    "        x = patcher.extract_patches(x)  # (bs, n_patches, h, w)\n",
    "\n",
    "        logits = net(x.reshape(-1, 1, patch_size, patch_size))  # (bs * n_patches, 1, patch_size, patch_size)\n",
    "        logits = logits.view(bs, -1, patch_size, patch_size)  # (bs, n_patches, patch_size, patch_size)\n",
    "        logits = patcher.merge_patches(logits).squeeze()  # (bs, h, w)\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # save probabilities maps\n",
    "        if save_preds:\n",
    "            for i in range(bs):\n",
    "                Image.fromarray((logits.cpu()[i].sigmoid() * (2**16 - 1)).numpy().astype(np.uint16)).save(f\"preds/{idx:04}.tif\")\n",
    "                idx += 1\n",
    "\n",
    "        pred = torch.where(logits.sigmoid() >= 0.5, 1, 0)\n",
    "\n",
    "        metric.process_batch(pred, y)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "    eval_loss /= len(eval_dl)\n",
    "    surface_dice = metric.compute()\n",
    "\n",
    "    return eval_loss, surface_dice\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval(save_preds=False):\n",
    "    overlap = 50\n",
    "    patcher = PatcherNew(h, w, p_size=patch_size, overlap=overlap)\n",
    "    eval_loss = 0.0\n",
    "    idx = 0\n",
    "    net.eval()\n",
    "    metric = SurfaceDiceMetric(n_batches=len(eval_dl), device=device)\n",
    "    for x, y in tqdm(eval_dl):\n",
    "        B, C, H, W = x.shape\n",
    "        x, y = x.to(device), y.to(device).float()\n",
    "        x = patcher.extract_patches(x)  # (B, n_patches, C, H, W)\n",
    "        x = x.flatten(end_dim=1)\n",
    "\n",
    "        logits = net(x)\n",
    "        logits = logits.unflatten(0, (B, -1))\n",
    "        logits = patcher.merge_patches(logits).squeeze()  # (bs, h, w)\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        # save probabilities maps\n",
    "        if save_preds:\n",
    "            for i in range(bs):\n",
    "                Image.fromarray((logits.cpu()[i].sigmoid() * (2**16 - 1)).numpy().astype(np.uint16)).save(f\"preds/{idx:04}.tif\")\n",
    "                idx += 1\n",
    "\n",
    "        pred = torch.where(logits.sigmoid() >= 0.5, 1, 0)\n",
    "\n",
    "        metric.process_batch(pred, y)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "    eval_loss /= len(eval_dl)\n",
    "    surface_dice = metric.compute()\n",
    "\n",
    "    return eval_loss, surface_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [01:39<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELOSS 0.00424858136896298, SURFACE_DICE 0.7274355888366699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_loss, surface_dice = eval_old(save_preds=False)\n",
    "print(f\"ELOSS {eval_loss}, SURFACE_DICE {surface_dice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [01:11<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELOSS 0.00424858136896298, SURFACE_DICE 0.7274355888366699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_loss, surface_dice = eval(save_preds=False)\n",
    "print(f\"ELOSS {eval_loss}, SURFACE_DICE {surface_dice}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
