{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ============== model CFG =============\n",
    "    model_name = \"Unet\"\n",
    "    backbone = \"se_resnext50_32x4d\"\n",
    "\n",
    "    in_chans = 5  # 65\n",
    "    # ============== _ CFG =============\n",
    "    image_size = 512\n",
    "    input_size = 512\n",
    "    tile_size = image_size\n",
    "    stride = tile_size // 4\n",
    "    drop_egde_pixel = 32\n",
    "\n",
    "    target_size = 1\n",
    "    chopping_percentile = 1e-3\n",
    "    # ============== fold =============\n",
    "    valid_id = 1\n",
    "    batch = 128\n",
    "    th_percentile = 0.0021\n",
    "    model_path = [\"data/se_resnext50_32x4d_19_loss0.12_score0.79_val_loss0.25_val_score0.79.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(mask):\n",
    "    pixel = mask.flatten()\n",
    "    pixel = np.concatenate([[0], pixel, [0]])\n",
    "    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n",
    "    run[1::2] -= run[::2]\n",
    "    rle = \" \".join(str(r) for r in run)\n",
    "    if rle == \"\":\n",
    "        rle = \"1 0\"\n",
    "    return rle\n",
    "\n",
    "\n",
    "def min_max_normalization(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"input.shape=(batch,f1,...)\"\"\"\n",
    "    shape = x.shape\n",
    "    if x.ndim > 2:\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "    min_ = x.min(dim=-1, keepdim=True)[0]\n",
    "    max_ = x.max(dim=-1, keepdim=True)[0]\n",
    "    if min_.mean() == 0 and max_.mean() == 1:\n",
    "        return x.reshape(shape)\n",
    "\n",
    "    x = (x - min_) / (max_ - min_ + 1e-9)\n",
    "    return x.reshape(shape)\n",
    "\n",
    "\n",
    "def norm_with_clip(x: torch.Tensor, smooth=1e-5):\n",
    "    dim = list(range(1, x.ndim))\n",
    "    mean = x.mean(dim=dim, keepdim=True)\n",
    "    std = x.std(dim=dim, keepdim=True)\n",
    "    x = (x - mean) / (std + smooth)\n",
    "    x[x > 5] = (x[x > 5] - 5) * 1e-3 + 5\n",
    "    x[x < -3] = (x[x < -3] + 3) * 1e-3 - 3\n",
    "    return x\n",
    "\n",
    "\n",
    "class Data_loader(Dataset):\n",
    "    def __init__(self, path, s=\"/images/\"):\n",
    "        self.paths = glob(path + f\"{s}*.tif\")\n",
    "        self.paths.sort()\n",
    "        self.bool = s == \"/labels/\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.paths[index], cv2.IMREAD_GRAYSCALE)\n",
    "        img = torch.from_numpy(img)\n",
    "        if self.bool:\n",
    "            img = img.to(torch.bool)\n",
    "        else:\n",
    "            img = img.to(torch.uint8)\n",
    "        return img\n",
    "\n",
    "\n",
    "def load_data(path, s):\n",
    "    data_loader = Data_loader(path, s)\n",
    "    data_loader = DataLoader(data_loader, batch_size=16, num_workers=2)\n",
    "    data = []\n",
    "    for x in tqdm(data_loader):\n",
    "        data.append(x)\n",
    "    x = torch.cat(data, dim=0)\n",
    "    ########################################################################\n",
    "    TH = x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH: int = np.partition(TH, index)[index]\n",
    "    x[x > TH] = int(TH)\n",
    "    ########################################################################\n",
    "    TH = x.reshape(-1).numpy()\n",
    "    index = -int(len(TH) * CFG.chopping_percentile)\n",
    "    TH: int = np.partition(TH, -index)[-index]\n",
    "    x[x < TH] = int(TH)\n",
    "    ########################################################################\n",
    "    # x=(min_max_normalization(x.to(torch.float16))*255).to(torch.uint8)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Pipeline_Dataset(Dataset):\n",
    "    def __init__(self, x, path):\n",
    "        self.img_paths = glob(path + \"/images/*\")\n",
    "        self.img_paths.sort()\n",
    "        self.in_chan = CFG.in_chans\n",
    "        z = torch.zeros(self.in_chan // 2, *x.shape[1:], dtype=x.dtype)\n",
    "        self.x = torch.cat((z, x, z), dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0] - self.in_chan + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index : index + self.in_chan]\n",
    "        return x, index\n",
    "\n",
    "    def get_mark(self, index):\n",
    "        id = self.img_paths[index].split(\"/\")[-3:]\n",
    "        id.pop(1)\n",
    "        id = \"_\".join(id)\n",
    "        return id[:-4]\n",
    "\n",
    "    def get_marks(self):\n",
    "        ids = []\n",
    "        for index in range(len(self)):\n",
    "            ids.append(self.get_mark(index))\n",
    "        return ids\n",
    "\n",
    "\n",
    "def add_edge(x: torch.Tensor, edge: int):\n",
    "    # x=(C,H,W)\n",
    "    # output=(C,H+2*edge,W+2*edge)\n",
    "    mean_ = int(x.to(torch.float32).mean())\n",
    "    x = torch.cat([x, torch.ones([x.shape[0], edge, x.shape[2]], dtype=x.dtype, device=x.device) * mean_], dim=1)\n",
    "    x = torch.cat([x, torch.ones([x.shape[0], x.shape[1], edge], dtype=x.dtype, device=x.device) * mean_], dim=2)\n",
    "    x = torch.cat([torch.ones([x.shape[0], edge, x.shape[2]], dtype=x.dtype, device=x.device) * mean_, x], dim=1)\n",
    "    x = torch.cat([torch.ones([x.shape[0], x.shape[1], edge], dtype=x.dtype, device=x.device) * mean_, x], dim=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:06<00:00, 21.09it/s]\n"
     ]
    }
   ],
   "source": [
    "output = [torch.load(\"output.pt\")]\n",
    "path = \"data/blood-vessel-segmentation/train/kidney_1_dense\"\n",
    "x = load_data(path, \"/images/\")\n",
    "ids = Pipeline_Dataset(x, path).get_marks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "TH = [x.flatten().numpy() for x in output]\n",
    "TH = np.concatenate(TH)\n",
    "index = -int(len(TH) * CFG.th_percentile)\n",
    "TH: int = np.partition(TH, index)[index]\n",
    "print(TH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (output[0] >= 128).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class KidneyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pred, msks_dir):\n",
    "        self.pred = pred.float()\n",
    "        self.msks_dir = msks_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pred)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        msk_path = self.msks_dir + f\"{idx:04}.tif\"\n",
    "\n",
    "        msk = Image.open(msk_path)\n",
    "        msk = np.array(msk)\n",
    "        slice_pred = self.pred[idx]\n",
    "\n",
    "        msk = torch.as_tensor(msk, dtype=torch.float32)\n",
    "        msk /= 255 # {0, 1} values\n",
    "\n",
    "        return slice_pred, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = KidneyDataset(pred, \"data/blood-vessel-segmentation/train/kidney_1_dense/labels/\")\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=5, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surface_dice import SurfaceDiceMetric\n",
    "metric = SurfaceDiceMetric(len(dl), device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 456/456 [00:20<00:00, 22.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for pred, target in tqdm(dl):\n",
    "    pred, target = pred.to(\"cuda:1\"), target.to(\"cuda:1\")\n",
    "    metric.process_batch(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.630912184715271"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
