{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "- [] I'm currently not evaluating with the full resolution images.\n",
    "- [] Put the net in eval mode during the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms as v1\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from surface_dice import SurfaceDiceMetric\n",
    "import wandb\n",
    "import albumentations as A\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_dir = \"/kaggle/input/blood-vessel-segmentation/\"\n",
    "train_dir = input_dir + \"train/\"\n",
    "\n",
    "# reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KidneyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs_dir, msks_dir, slices_ids, transforms=None):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.msks_dir = msks_dir\n",
    "        self.slices_ids = slices_ids\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_id = self.slices_ids[idx]\n",
    "        img_path = self.imgs_dir + slice_id\n",
    "        msk_path = self.msks_dir + slice_id\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        msk = Image.open(msk_path)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            msk = np.array(msk)\n",
    "\n",
    "            t = self.transforms(image=img, mask=msk)\n",
    "            img = t[\"image\"]\n",
    "            msk = t[\"mask\"]\n",
    "            \n",
    "            img = torch.from_numpy(img)[None, :]\n",
    "            msk = torch.as_tensor(msk, dtype=torch.float32)\n",
    "            img = img / img.max()\n",
    "            msk /= 255 \n",
    "\n",
    "        return img, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_dir = f\"{train_dir}kidney_1_dense/images/\"\n",
    "msks_dir = f\"{train_dir}kidney_1_dense/labels/\"\n",
    "slices_ids = sorted(os.listdir(imgs_dir))\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(224, 224)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = KidneyDataset(\n",
    "    imgs_dir=imgs_dir,\n",
    "    msks_dir=msks_dir,\n",
    "    slices_ids=slices_ids,\n",
    "    transforms=transforms,\n",
    ")\n",
    "\n",
    "print(\"Dataset length:\", len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "num_workers = os.cpu_count()\n",
    "train_dl = DataLoader(ds, batch_size=bs, num_workers=num_workers, shuffle=False, persistent_workers=True)\n",
    "print(\"DataLoader length:\", len(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "net = smp.Unet(\n",
    "    encoder_name=\"timm-mobilenetv3_small_075\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    ")\n",
    "print(f\"Number of params: {sum([p.nelement() for p in net.parameters()]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((16, 512, 512))\n",
    "y = torch.randint(2, (16, 512, 512), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.nn.functional.binary_cross_entropy_with_logits(x, y))\n",
    "print(torch.nn.functional.binary_cross_entropy_with_logits(x, y, pos_weight=torch.tensor(3)))\n",
    "print(torch.nn.functional.binary_cross_entropy_with_logits(x, y, pos_weight=torch.tensor([3])))\n",
    "print(torch.nn.functional.binary_cross_entropy_with_logits(x, y, pos_weight=torch.tensor([3]).view(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-torch.where(y == 1, x.sigmoid().log(), (1 - x.sigmoid()).log()).mean())\n",
    "print(-torch.where(y == 1, 3 * x.sigmoid().log(), (1 - x.sigmoid()).log()).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine positive weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "pos = 0\n",
    "for _, y in tqdm(train_dl):\n",
    "    total += y.nelement()\n",
    "    pos += y.sum().long().item()\n",
    "\n",
    "pos_weight = total / pos - 1\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(lr=lr, params=net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = net(x).squeeze()\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.where(logits.detach().sigmoid() >= 0.5, 1, 0)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dl)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(dl):\n",
    "    eval_loss = 0.0\n",
    "    net.train()  # TODO: Put in eval mode\n",
    "    metric = SurfaceDiceMetric(n_batches=len(dl), device=device)\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = net(x).squeeze()\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        pred = torch.where(logits.sigmoid() >= 0.5, 1, 0)\n",
    "        metric.process_batch(pred, y)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "    eval_loss /= len(dl)\n",
    "    surface_dice = metric.compute()\n",
    "\n",
    "    return eval_loss, surface_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "losses = []\n",
    "dices = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train()\n",
    "    eval_loss, surface_dice = eval(train_dl)\n",
    "    print(f\"EPOCH {epoch}, DICE {surface_dice:.4f} TLOSS {train_loss:.4f}, ELOSS {eval_loss:.4f}\")\n",
    "    losses.append(train_loss)\n",
    "    dices.append(surface_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15, 7))\n",
    "axs[0].set_title(\"Training loss\")\n",
    "axs[1].set_title(\"Surface Dice\")\n",
    "axs[0].plot(losses)\n",
    "axs[1].plot(dices, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x = x.cuda()\n",
    "probs = net(x).squeeze().detach().sigmoid().cpu()\n",
    "print(\n",
    "    f\"loss with pos_weight: {torch.nn.functional.binary_cross_entropy_with_logits(net(x).squeeze().detach().cpu(), y, pos_weight=torch.tensor(pos_weight)).item():.5f}\"\n",
    ")\n",
    "print(\n",
    "    f\"loss without pos_weight: {torch.nn.functional.binary_cross_entropy_with_logits(net(x).squeeze().detach().cpu(), y).item():.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randint(bs, (1,)).item()\n",
    "threshold = 0.5\n",
    "print(idx)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 7))\n",
    "axs[0].set_title(\"Image\")\n",
    "axs[1].set_title(\"Groud Truth\")\n",
    "axs[2].set_title(\"Probabilities\")\n",
    "axs[3].set_title(f\"Prediction with p>{threshold}\")\n",
    "axs[0].imshow(x.cpu()[idx].squeeze())\n",
    "axs[1].imshow(y[idx])\n",
    "axs[2].imshow(probs[idx])\n",
    "axs[3].imshow(torch.where(probs >= threshold, 1, 0)[idx])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
